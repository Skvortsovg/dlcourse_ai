{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_fc1\n",
      "Gradient check passed!\n",
      "Checking gradient for B_fc1\n",
      "Gradient check passed!\n",
      "Checking gradient for W_fc2\n",
      "Gradient check passed!\n",
      "Checking gradient for B_fc2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_fc1\n",
      "Gradient check passed!\n",
      "Checking gradient for B_fc1\n",
      "Gradient check passed!\n",
      "Checking gradient for W_fc2\n",
      "Gradient check passed!\n",
      "Checking gradient for B_fc2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import TwoLayerNet\n",
    "from metrics import multiclass_accuracy\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.311037, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257201, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299850, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.211899, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283499, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.189323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225371, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.346309, Train accuracy: 0.207556, val accuracy: 0.215000\n",
      "Loss: 2.125317, Train accuracy: 0.234333, val accuracy: 0.238000\n",
      "Loss: 2.107688, Train accuracy: 0.258222, val accuracy: 0.258000\n",
      "Loss: 2.038596, Train accuracy: 0.268556, val accuracy: 0.267000\n",
      "Loss: 2.176081, Train accuracy: 0.282889, val accuracy: 0.290000\n",
      "Loss: 1.980822, Train accuracy: 0.313778, val accuracy: 0.317000\n",
      "Loss: 1.734718, Train accuracy: 0.345556, val accuracy: 0.345000\n",
      "Loss: 1.712075, Train accuracy: 0.381000, val accuracy: 0.376000\n",
      "Loss: 1.568853, Train accuracy: 0.400444, val accuracy: 0.392000\n",
      "Loss: 1.724897, Train accuracy: 0.427111, val accuracy: 0.416000\n",
      "Loss: 1.778175, Train accuracy: 0.451667, val accuracy: 0.444000\n",
      "Loss: 1.503028, Train accuracy: 0.472000, val accuracy: 0.469000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb90d591f98>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.258367, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172082, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315996, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.084472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201596, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.324979, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.082897, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.097376, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.018531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.007963, Train accuracy: 0.218111, val accuracy: 0.224000\n",
      "Loss: 2.037898, Train accuracy: 0.238556, val accuracy: 0.241000\n",
      "Loss: 2.157339, Train accuracy: 0.258556, val accuracy: 0.258000\n",
      "Loss: 1.624162, Train accuracy: 0.269000, val accuracy: 0.268000\n",
      "Loss: 1.854634, Train accuracy: 0.284778, val accuracy: 0.285000\n",
      "Loss: 1.745950, Train accuracy: 0.305222, val accuracy: 0.307000\n",
      "Loss: 1.880715, Train accuracy: 0.337000, val accuracy: 0.337000\n",
      "Loss: 2.133960, Train accuracy: 0.366111, val accuracy: 0.373000\n",
      "Loss: 1.589423, Train accuracy: 0.389556, val accuracy: 0.385000\n",
      "Loss: 1.855956, Train accuracy: 0.414222, val accuracy: 0.405000\n",
      "Loss: 1.648145, Train accuracy: 0.428111, val accuracy: 0.412000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5 * initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.254431, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.046629, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220667, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269846, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.211430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188904, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.327077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207343, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.194498, Train accuracy: 0.197333, val accuracy: 0.207000\n",
      "Loss: 1.972097, Train accuracy: 0.212222, val accuracy: 0.220000\n",
      "Loss: 2.043638, Train accuracy: 0.226667, val accuracy: 0.230000\n",
      "Loss: 2.079393, Train accuracy: 0.242667, val accuracy: 0.247000\n",
      "Loss: 2.163382, Train accuracy: 0.253778, val accuracy: 0.250000\n",
      "Loss: 2.252759, Train accuracy: 0.266556, val accuracy: 0.262000\n",
      "Loss: 2.133518, Train accuracy: 0.272778, val accuracy: 0.270000\n",
      "Loss: 2.103119, Train accuracy: 0.277000, val accuracy: 0.276000\n",
      "Loss: 1.984771, Train accuracy: 0.280667, val accuracy: 0.282000\n",
      "Loss: 2.080321, Train accuracy: 0.282667, val accuracy: 0.289000\n",
      "Loss: 2.298271, Train accuracy: 0.307778, val accuracy: 0.315000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-3, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.339114, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.312515, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.294804, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.302629, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.302958, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.326006, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.302982, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.281074, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.205450, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.250561, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.010600, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.997571, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.054280, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.224979, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.751031, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.776247, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.093275, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.430756, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.120340, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.426604, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.762091, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.659832, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.803935, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.510745, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.894231, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.003421, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.650026, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.732777, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.736898, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.288453, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.714037, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.800221, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.705169, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.882726, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.562121, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.149654, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.325582, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.488463, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 0.967819, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.698969, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.372793, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.084045, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.045404, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.787015, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.449710, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.352490, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.267119, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.151222, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.615573, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.278150, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.321631, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.469319, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.595051, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.939783, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.846994, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 0.847954, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.111184, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.667007, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 0.779736, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.953051, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.214839, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.449858, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.496407, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.162732, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.291436, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.290172, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.284701, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.490558, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.654337, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.709158, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.574475, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.654866, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.028698, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.974784, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.571480, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.673483, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.329211, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.463968, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.853485, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.222719, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.301133, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.180848, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.565007, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.283688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.983032, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.169949, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.563481, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.618592, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.183593, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.283868, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.367878, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.215435, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.265975, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.099814, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.359615, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.838553, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.655032, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.583557, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.317644, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.491750, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249800, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.190106, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.236771, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.452478, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.113189, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.373033, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.405997, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.503390, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.434238, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.270018, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.136330, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.184766, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.095512, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.213658, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.230182, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.318654, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.071474, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.103190, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.032746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.205438, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.317152, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.156508, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.208007, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.309114, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.310086, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.132040, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.447273, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.170638, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160649, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.437978, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.376946, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460407, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.388319, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.416314, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.164076, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.217434, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.367667, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.388327, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.225609, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.278708, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.142615, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.224222, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.195536, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.349267, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.420155, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.491107, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.368865, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.204516, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.240863, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.182918, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303778, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.263931, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.183918, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 3.041951, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 3.638033, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.382135, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.398126, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 1.407563, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 3.730900, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.329557, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 4.929495, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: 3.335847, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.476671, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.417217, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.213315, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.091245, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.362356, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.023231, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.156523, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.184518, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 150, reg = 0)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=4e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=100 batch_size=64\n",
      "Loss: 2.268704, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.090935, Train accuracy: 0.215556, val accuracy: 0.215000\n",
      "Loss: 2.040243, Train accuracy: 0.267222, val accuracy: 0.278000\n",
      "Loss: 2.007209, Train accuracy: 0.340222, val accuracy: 0.345000\n",
      "Loss: 1.446407, Train accuracy: 0.427667, val accuracy: 0.414000\n",
      "Loss: 1.313518, Train accuracy: 0.501556, val accuracy: 0.504000\n",
      "Loss: 1.584089, Train accuracy: 0.529667, val accuracy: 0.536000\n",
      "Loss: 1.371615, Train accuracy: 0.569000, val accuracy: 0.553000\n",
      "Loss: 1.237298, Train accuracy: 0.625667, val accuracy: 0.608000\n",
      "Loss: 1.314605, Train accuracy: 0.625667, val accuracy: 0.615000\n",
      "Loss: 1.400989, Train accuracy: 0.649111, val accuracy: 0.628000\n",
      "Loss: 1.231049, Train accuracy: 0.650889, val accuracy: 0.652000\n",
      "Loss: 0.989726, Train accuracy: 0.698444, val accuracy: 0.682000\n",
      "Loss: 0.894887, Train accuracy: 0.711889, val accuracy: 0.690000\n",
      "Loss: 0.765668, Train accuracy: 0.709000, val accuracy: 0.685000\n",
      "Loss: 0.815918, Train accuracy: 0.717222, val accuracy: 0.688000\n",
      "Loss: 0.797177, Train accuracy: 0.690000, val accuracy: 0.661000\n",
      "Loss: 0.699224, Train accuracy: 0.738889, val accuracy: 0.696000\n",
      "Loss: 0.863652, Train accuracy: 0.737444, val accuracy: 0.701000\n",
      "Loss: 0.924448, Train accuracy: 0.744556, val accuracy: 0.706000\n",
      "Loss: 0.725214, Train accuracy: 0.761444, val accuracy: 0.717000\n",
      "Loss: 0.695587, Train accuracy: 0.766333, val accuracy: 0.708000\n",
      "Loss: 1.070362, Train accuracy: 0.749333, val accuracy: 0.689000\n",
      "Loss: 0.741368, Train accuracy: 0.776778, val accuracy: 0.706000\n",
      "Loss: 0.825325, Train accuracy: 0.754333, val accuracy: 0.695000\n",
      "Loss: 0.604689, Train accuracy: 0.784222, val accuracy: 0.699000\n",
      "Loss: 0.564855, Train accuracy: 0.804111, val accuracy: 0.734000\n",
      "Loss: 0.580630, Train accuracy: 0.817333, val accuracy: 0.729000\n",
      "Loss: 0.385288, Train accuracy: 0.827889, val accuracy: 0.739000\n",
      "Loss: 0.533996, Train accuracy: 0.805333, val accuracy: 0.724000\n",
      "Loss: 0.845691, Train accuracy: 0.801778, val accuracy: 0.713000\n",
      "Loss: 0.652610, Train accuracy: 0.824111, val accuracy: 0.725000\n",
      "Loss: 0.836013, Train accuracy: 0.785111, val accuracy: 0.694000\n",
      "Loss: 0.781690, Train accuracy: 0.749111, val accuracy: 0.678000\n",
      "Loss: 0.439621, Train accuracy: 0.809000, val accuracy: 0.711000\n",
      "Loss: 0.386796, Train accuracy: 0.853667, val accuracy: 0.729000\n",
      "Loss: 0.427003, Train accuracy: 0.852222, val accuracy: 0.745000\n",
      "Loss: 0.547813, Train accuracy: 0.840000, val accuracy: 0.722000\n",
      "Loss: 0.343057, Train accuracy: 0.865778, val accuracy: 0.740000\n",
      "Loss: 0.343793, Train accuracy: 0.860111, val accuracy: 0.730000\n",
      "Loss: 0.835745, Train accuracy: 0.844444, val accuracy: 0.716000\n",
      "Loss: 0.460011, Train accuracy: 0.857222, val accuracy: 0.720000\n",
      "Loss: 0.902585, Train accuracy: 0.837778, val accuracy: 0.713000\n",
      "Loss: 0.352187, Train accuracy: 0.886778, val accuracy: 0.735000\n",
      "Loss: 0.216824, Train accuracy: 0.893889, val accuracy: 0.739000\n",
      "Loss: 0.123099, Train accuracy: 0.882222, val accuracy: 0.743000\n",
      "Loss: 0.449056, Train accuracy: 0.865222, val accuracy: 0.729000\n",
      "Loss: 0.495231, Train accuracy: 0.895444, val accuracy: 0.731000\n",
      "Loss: 0.463523, Train accuracy: 0.907667, val accuracy: 0.743000\n",
      "Loss: 0.291024, Train accuracy: 0.898111, val accuracy: 0.736000\n",
      "Loss: 0.591571, Train accuracy: 0.903222, val accuracy: 0.752000\n",
      "Loss: 0.274392, Train accuracy: 0.872222, val accuracy: 0.712000\n",
      "Loss: 0.416363, Train accuracy: 0.906889, val accuracy: 0.753000\n",
      "Loss: 0.187213, Train accuracy: 0.910556, val accuracy: 0.750000\n",
      "Loss: 0.572260, Train accuracy: 0.897667, val accuracy: 0.734000\n",
      "Loss: 0.724164, Train accuracy: 0.871000, val accuracy: 0.707000\n",
      "Loss: 0.309072, Train accuracy: 0.912222, val accuracy: 0.747000\n",
      "Loss: 0.442600, Train accuracy: 0.882333, val accuracy: 0.708000\n",
      "Loss: 0.167974, Train accuracy: 0.918667, val accuracy: 0.749000\n",
      "Loss: 0.336313, Train accuracy: 0.906667, val accuracy: 0.734000\n",
      "Loss: 0.367086, Train accuracy: 0.908111, val accuracy: 0.733000\n",
      "Loss: 0.269746, Train accuracy: 0.905111, val accuracy: 0.746000\n",
      "Loss: 0.517455, Train accuracy: 0.929333, val accuracy: 0.742000\n",
      "Loss: 0.393132, Train accuracy: 0.920444, val accuracy: 0.737000\n",
      "Loss: 0.359014, Train accuracy: 0.929000, val accuracy: 0.742000\n",
      "Loss: 0.406661, Train accuracy: 0.922000, val accuracy: 0.743000\n",
      "Loss: 0.362024, Train accuracy: 0.917444, val accuracy: 0.726000\n",
      "Loss: 0.367705, Train accuracy: 0.886556, val accuracy: 0.736000\n",
      "Loss: 0.204818, Train accuracy: 0.935556, val accuracy: 0.748000\n",
      "Loss: 0.687636, Train accuracy: 0.879333, val accuracy: 0.718000\n",
      "Loss: 0.257777, Train accuracy: 0.916444, val accuracy: 0.743000\n",
      "Loss: 0.345966, Train accuracy: 0.932222, val accuracy: 0.749000\n",
      "Loss: 0.207648, Train accuracy: 0.943333, val accuracy: 0.752000\n",
      "Loss: 0.125882, Train accuracy: 0.913889, val accuracy: 0.735000\n",
      "Loss: 0.231723, Train accuracy: 0.934444, val accuracy: 0.738000\n",
      "Loss: 0.329288, Train accuracy: 0.954556, val accuracy: 0.760000\n",
      "Loss: 0.204950, Train accuracy: 0.930111, val accuracy: 0.758000\n",
      "Loss: 0.335319, Train accuracy: 0.950333, val accuracy: 0.745000\n",
      "Loss: 0.200753, Train accuracy: 0.945778, val accuracy: 0.742000\n",
      "Loss: 0.316695, Train accuracy: 0.939111, val accuracy: 0.741000\n",
      "Loss: 0.220796, Train accuracy: 0.958444, val accuracy: 0.753000\n",
      "Loss: 0.176741, Train accuracy: 0.933667, val accuracy: 0.727000\n",
      "Loss: 0.390618, Train accuracy: 0.930222, val accuracy: 0.734000\n",
      "Loss: 0.057815, Train accuracy: 0.948111, val accuracy: 0.749000\n",
      "Loss: 0.133298, Train accuracy: 0.936444, val accuracy: 0.734000\n",
      "Loss: 0.241366, Train accuracy: 0.952000, val accuracy: 0.748000\n",
      "Loss: 0.276279, Train accuracy: 0.901222, val accuracy: 0.717000\n",
      "Loss: 0.088526, Train accuracy: 0.961333, val accuracy: 0.749000\n",
      "Loss: 0.175873, Train accuracy: 0.939000, val accuracy: 0.739000\n",
      "Loss: 0.243736, Train accuracy: 0.928333, val accuracy: 0.733000\n",
      "Loss: 0.112368, Train accuracy: 0.974333, val accuracy: 0.760000\n",
      "Loss: 0.230788, Train accuracy: 0.950222, val accuracy: 0.739000\n",
      "Loss: 0.064373, Train accuracy: 0.972000, val accuracy: 0.753000\n",
      "Loss: 0.105176, Train accuracy: 0.975333, val accuracy: 0.752000\n",
      "Loss: 0.182957, Train accuracy: 0.940000, val accuracy: 0.740000\n",
      "Loss: 0.143327, Train accuracy: 0.967222, val accuracy: 0.757000\n",
      "Loss: 0.252658, Train accuracy: 0.960778, val accuracy: 0.747000\n",
      "Loss: 0.126351, Train accuracy: 0.970111, val accuracy: 0.747000\n",
      "Loss: 0.303513, Train accuracy: 0.973444, val accuracy: 0.756000\n",
      "best val acc = 0.76, epoch_n=76\n",
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=100 batch_size=50\n",
      "Loss: 2.220929, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.135276, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.051983, Train accuracy: 0.271111, val accuracy: 0.270000\n",
      "Loss: 1.646277, Train accuracy: 0.366444, val accuracy: 0.368000\n",
      "Loss: 1.512863, Train accuracy: 0.462000, val accuracy: 0.467000\n",
      "Loss: 1.426247, Train accuracy: 0.560111, val accuracy: 0.538000\n",
      "Loss: 1.368397, Train accuracy: 0.587556, val accuracy: 0.586000\n",
      "Loss: 1.179591, Train accuracy: 0.630889, val accuracy: 0.629000\n",
      "Loss: 1.012615, Train accuracy: 0.666333, val accuracy: 0.662000\n",
      "Loss: 1.161013, Train accuracy: 0.676444, val accuracy: 0.665000\n",
      "Loss: 1.058880, Train accuracy: 0.702111, val accuracy: 0.689000\n",
      "Loss: 1.028308, Train accuracy: 0.707444, val accuracy: 0.669000\n",
      "Loss: 1.512358, Train accuracy: 0.710444, val accuracy: 0.673000\n",
      "Loss: 0.901068, Train accuracy: 0.716667, val accuracy: 0.665000\n",
      "Loss: 0.819505, Train accuracy: 0.749111, val accuracy: 0.710000\n",
      "Loss: 0.841790, Train accuracy: 0.766556, val accuracy: 0.718000\n",
      "Loss: 1.039146, Train accuracy: 0.754889, val accuracy: 0.703000\n",
      "Loss: 0.904795, Train accuracy: 0.770000, val accuracy: 0.705000\n",
      "Loss: 0.429896, Train accuracy: 0.773556, val accuracy: 0.725000\n",
      "Loss: 0.711015, Train accuracy: 0.786222, val accuracy: 0.726000\n",
      "Loss: 0.755682, Train accuracy: 0.802111, val accuracy: 0.730000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.730940, Train accuracy: 0.799222, val accuracy: 0.716000\n",
      "Loss: 0.662643, Train accuracy: 0.812000, val accuracy: 0.728000\n",
      "Loss: 0.882425, Train accuracy: 0.828889, val accuracy: 0.733000\n",
      "Loss: 0.511988, Train accuracy: 0.824111, val accuracy: 0.732000\n",
      "Loss: 0.544062, Train accuracy: 0.806111, val accuracy: 0.722000\n",
      "Loss: 0.409449, Train accuracy: 0.844333, val accuracy: 0.746000\n",
      "Loss: 0.717142, Train accuracy: 0.823889, val accuracy: 0.722000\n",
      "Loss: 0.486265, Train accuracy: 0.841444, val accuracy: 0.730000\n",
      "Loss: 0.761491, Train accuracy: 0.831778, val accuracy: 0.715000\n",
      "Loss: 0.743702, Train accuracy: 0.828778, val accuracy: 0.718000\n",
      "Loss: 0.475338, Train accuracy: 0.868556, val accuracy: 0.745000\n",
      "Loss: 0.437401, Train accuracy: 0.865889, val accuracy: 0.744000\n",
      "Loss: 0.402048, Train accuracy: 0.873111, val accuracy: 0.740000\n",
      "Loss: 0.577190, Train accuracy: 0.854778, val accuracy: 0.725000\n",
      "Loss: 0.676567, Train accuracy: 0.877778, val accuracy: 0.749000\n",
      "Loss: 0.508559, Train accuracy: 0.825222, val accuracy: 0.718000\n",
      "Loss: 0.460207, Train accuracy: 0.875667, val accuracy: 0.743000\n",
      "Loss: 0.397452, Train accuracy: 0.893333, val accuracy: 0.752000\n",
      "Loss: 0.420303, Train accuracy: 0.879889, val accuracy: 0.739000\n",
      "Loss: 0.581525, Train accuracy: 0.892444, val accuracy: 0.755000\n",
      "Loss: 0.341262, Train accuracy: 0.881111, val accuracy: 0.731000\n",
      "Loss: 0.481260, Train accuracy: 0.884667, val accuracy: 0.752000\n",
      "Loss: 0.384408, Train accuracy: 0.884556, val accuracy: 0.755000\n",
      "Loss: 0.353458, Train accuracy: 0.913222, val accuracy: 0.764000\n",
      "Loss: 0.573917, Train accuracy: 0.896444, val accuracy: 0.738000\n",
      "Loss: 0.340560, Train accuracy: 0.905778, val accuracy: 0.749000\n",
      "Loss: 0.415056, Train accuracy: 0.887222, val accuracy: 0.730000\n",
      "Loss: 0.195216, Train accuracy: 0.914111, val accuracy: 0.763000\n",
      "Loss: 0.330188, Train accuracy: 0.923333, val accuracy: 0.756000\n",
      "Loss: 0.262046, Train accuracy: 0.921444, val accuracy: 0.760000\n",
      "Loss: 0.282297, Train accuracy: 0.887000, val accuracy: 0.733000\n",
      "Loss: 0.497632, Train accuracy: 0.893889, val accuracy: 0.744000\n",
      "Loss: 0.331573, Train accuracy: 0.900778, val accuracy: 0.724000\n",
      "Loss: 0.273097, Train accuracy: 0.927333, val accuracy: 0.757000\n",
      "Loss: 0.414118, Train accuracy: 0.917222, val accuracy: 0.744000\n",
      "Loss: 0.257376, Train accuracy: 0.932778, val accuracy: 0.758000\n",
      "Loss: 0.356215, Train accuracy: 0.908444, val accuracy: 0.743000\n",
      "Loss: 0.498805, Train accuracy: 0.913667, val accuracy: 0.749000\n",
      "Loss: 0.204522, Train accuracy: 0.941000, val accuracy: 0.749000\n",
      "Loss: 0.296758, Train accuracy: 0.934778, val accuracy: 0.754000\n",
      "Loss: 0.195642, Train accuracy: 0.940667, val accuracy: 0.765000\n",
      "Loss: 0.181376, Train accuracy: 0.943111, val accuracy: 0.756000\n",
      "Loss: 0.401847, Train accuracy: 0.904000, val accuracy: 0.734000\n",
      "Loss: 0.367197, Train accuracy: 0.941444, val accuracy: 0.759000\n",
      "Loss: 0.319530, Train accuracy: 0.915778, val accuracy: 0.736000\n",
      "Loss: 0.372692, Train accuracy: 0.912111, val accuracy: 0.743000\n",
      "Loss: 0.171685, Train accuracy: 0.957111, val accuracy: 0.758000\n",
      "Loss: 0.263720, Train accuracy: 0.925778, val accuracy: 0.743000\n",
      "Loss: 0.383681, Train accuracy: 0.946889, val accuracy: 0.741000\n",
      "Loss: 0.266435, Train accuracy: 0.933000, val accuracy: 0.742000\n",
      "Loss: 0.163594, Train accuracy: 0.942889, val accuracy: 0.756000\n",
      "Loss: 0.152897, Train accuracy: 0.936556, val accuracy: 0.753000\n",
      "Loss: 0.168240, Train accuracy: 0.956444, val accuracy: 0.754000\n",
      "Loss: 0.089168, Train accuracy: 0.964333, val accuracy: 0.762000\n",
      "Loss: 0.272411, Train accuracy: 0.936222, val accuracy: 0.743000\n",
      "Loss: 0.218583, Train accuracy: 0.955111, val accuracy: 0.753000\n",
      "Loss: 0.178829, Train accuracy: 0.951667, val accuracy: 0.758000\n",
      "Loss: 0.234675, Train accuracy: 0.966000, val accuracy: 0.761000\n",
      "Loss: 0.592541, Train accuracy: 0.880333, val accuracy: 0.716000\n",
      "Loss: 0.243198, Train accuracy: 0.954000, val accuracy: 0.754000\n",
      "Loss: 0.115878, Train accuracy: 0.966778, val accuracy: 0.751000\n",
      "Loss: 0.091480, Train accuracy: 0.958333, val accuracy: 0.761000\n",
      "Loss: 0.114288, Train accuracy: 0.962444, val accuracy: 0.751000\n",
      "Loss: 0.267020, Train accuracy: 0.960333, val accuracy: 0.756000\n",
      "Loss: 0.156662, Train accuracy: 0.972222, val accuracy: 0.749000\n",
      "Loss: 0.119345, Train accuracy: 0.945667, val accuracy: 0.738000\n",
      "Loss: 0.154347, Train accuracy: 0.963333, val accuracy: 0.760000\n",
      "Loss: 0.103691, Train accuracy: 0.973000, val accuracy: 0.751000\n",
      "Loss: 0.111578, Train accuracy: 0.973222, val accuracy: 0.756000\n",
      "Loss: 0.144872, Train accuracy: 0.965667, val accuracy: 0.752000\n",
      "Loss: 0.174227, Train accuracy: 0.964556, val accuracy: 0.751000\n",
      "Loss: 0.133579, Train accuracy: 0.966889, val accuracy: 0.752000\n",
      "Loss: 0.117396, Train accuracy: 0.969556, val accuracy: 0.748000\n",
      "Loss: 0.086607, Train accuracy: 0.981000, val accuracy: 0.742000\n",
      "Loss: 0.151971, Train accuracy: 0.926333, val accuracy: 0.736000\n",
      "Loss: 0.066084, Train accuracy: 0.980111, val accuracy: 0.768000\n",
      "Loss: 0.142905, Train accuracy: 0.978444, val accuracy: 0.753000\n",
      "Loss: 0.079811, Train accuracy: 0.961667, val accuracy: 0.750000\n",
      "Loss: 0.269856, Train accuracy: 0.979778, val accuracy: 0.755000\n",
      "best val acc = 0.768, epoch_n=96\n",
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=100 batch_size=80\n",
      "Loss: 2.243849, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.197782, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.044857, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145780, Train accuracy: 0.231889, val accuracy: 0.244000\n",
      "Loss: 2.108882, Train accuracy: 0.258889, val accuracy: 0.257000\n",
      "Loss: 1.698196, Train accuracy: 0.302778, val accuracy: 0.313000\n",
      "Loss: 1.707915, Train accuracy: 0.406556, val accuracy: 0.386000\n",
      "Loss: 1.911641, Train accuracy: 0.454333, val accuracy: 0.458000\n",
      "Loss: 1.414152, Train accuracy: 0.522000, val accuracy: 0.519000\n",
      "Loss: 1.373357, Train accuracy: 0.559667, val accuracy: 0.552000\n",
      "Loss: 1.277013, Train accuracy: 0.539667, val accuracy: 0.546000\n",
      "Loss: 1.342741, Train accuracy: 0.610111, val accuracy: 0.595000\n",
      "Loss: 0.887683, Train accuracy: 0.655556, val accuracy: 0.627000\n",
      "Loss: 1.209652, Train accuracy: 0.663222, val accuracy: 0.653000\n",
      "Loss: 0.961301, Train accuracy: 0.680778, val accuracy: 0.672000\n",
      "Loss: 1.066222, Train accuracy: 0.684778, val accuracy: 0.650000\n",
      "Loss: 0.881273, Train accuracy: 0.679667, val accuracy: 0.654000\n",
      "Loss: 1.052282, Train accuracy: 0.705778, val accuracy: 0.683000\n",
      "Loss: 1.066835, Train accuracy: 0.724222, val accuracy: 0.702000\n",
      "Loss: 1.113972, Train accuracy: 0.731667, val accuracy: 0.694000\n",
      "Loss: 0.596399, Train accuracy: 0.704556, val accuracy: 0.670000\n",
      "Loss: 0.849323, Train accuracy: 0.710667, val accuracy: 0.668000\n",
      "Loss: 0.605948, Train accuracy: 0.676444, val accuracy: 0.655000\n",
      "Loss: 0.710372, Train accuracy: 0.747889, val accuracy: 0.690000\n",
      "Loss: 0.905467, Train accuracy: 0.745667, val accuracy: 0.698000\n",
      "Loss: 0.767375, Train accuracy: 0.727333, val accuracy: 0.672000\n",
      "Loss: 0.785936, Train accuracy: 0.761000, val accuracy: 0.703000\n",
      "Loss: 0.884384, Train accuracy: 0.779444, val accuracy: 0.706000\n",
      "Loss: 0.561110, Train accuracy: 0.772111, val accuracy: 0.711000\n",
      "Loss: 1.035349, Train accuracy: 0.734333, val accuracy: 0.674000\n",
      "Loss: 0.767561, Train accuracy: 0.773889, val accuracy: 0.696000\n",
      "Loss: 0.462768, Train accuracy: 0.808778, val accuracy: 0.720000\n",
      "Loss: 0.590307, Train accuracy: 0.804889, val accuracy: 0.714000\n",
      "Loss: 0.628729, Train accuracy: 0.815444, val accuracy: 0.720000\n",
      "Loss: 0.469477, Train accuracy: 0.786111, val accuracy: 0.691000\n",
      "Loss: 0.606294, Train accuracy: 0.807111, val accuracy: 0.717000\n",
      "Loss: 0.534203, Train accuracy: 0.802444, val accuracy: 0.727000\n",
      "Loss: 0.522614, Train accuracy: 0.768778, val accuracy: 0.693000\n",
      "Loss: 0.613256, Train accuracy: 0.822333, val accuracy: 0.720000\n",
      "Loss: 0.466757, Train accuracy: 0.840000, val accuracy: 0.731000\n",
      "Loss: 0.408193, Train accuracy: 0.847333, val accuracy: 0.744000\n",
      "Loss: 0.482241, Train accuracy: 0.837778, val accuracy: 0.734000\n",
      "Loss: 0.461489, Train accuracy: 0.852222, val accuracy: 0.731000\n",
      "Loss: 0.445338, Train accuracy: 0.783667, val accuracy: 0.690000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.503767, Train accuracy: 0.848444, val accuracy: 0.732000\n",
      "Loss: 0.311804, Train accuracy: 0.858222, val accuracy: 0.740000\n",
      "Loss: 0.486988, Train accuracy: 0.830556, val accuracy: 0.714000\n",
      "Loss: 0.407338, Train accuracy: 0.860222, val accuracy: 0.735000\n",
      "Loss: 0.367389, Train accuracy: 0.871556, val accuracy: 0.734000\n",
      "Loss: 0.518513, Train accuracy: 0.873111, val accuracy: 0.736000\n",
      "Loss: 0.390474, Train accuracy: 0.879667, val accuracy: 0.741000\n",
      "Loss: 0.479368, Train accuracy: 0.870778, val accuracy: 0.728000\n",
      "Loss: 0.401391, Train accuracy: 0.880333, val accuracy: 0.752000\n",
      "Loss: 0.550201, Train accuracy: 0.842667, val accuracy: 0.705000\n",
      "Loss: 0.458198, Train accuracy: 0.822778, val accuracy: 0.710000\n",
      "Loss: 0.501546, Train accuracy: 0.819778, val accuracy: 0.706000\n",
      "Loss: 0.288947, Train accuracy: 0.897333, val accuracy: 0.738000\n",
      "Loss: 0.348974, Train accuracy: 0.883889, val accuracy: 0.720000\n",
      "Loss: 0.584921, Train accuracy: 0.890556, val accuracy: 0.743000\n",
      "Loss: 0.452616, Train accuracy: 0.823667, val accuracy: 0.694000\n",
      "Loss: 0.336387, Train accuracy: 0.901667, val accuracy: 0.739000\n",
      "Loss: 0.616452, Train accuracy: 0.857222, val accuracy: 0.725000\n",
      "Loss: 0.438726, Train accuracy: 0.913333, val accuracy: 0.748000\n",
      "Loss: 0.741083, Train accuracy: 0.834111, val accuracy: 0.698000\n",
      "Loss: 0.357000, Train accuracy: 0.912222, val accuracy: 0.741000\n",
      "Loss: 0.379251, Train accuracy: 0.903778, val accuracy: 0.729000\n",
      "Loss: 0.339501, Train accuracy: 0.878889, val accuracy: 0.719000\n",
      "Loss: 0.353420, Train accuracy: 0.906222, val accuracy: 0.741000\n",
      "Loss: 0.303871, Train accuracy: 0.918111, val accuracy: 0.745000\n",
      "Loss: 0.532920, Train accuracy: 0.867889, val accuracy: 0.712000\n",
      "Loss: 0.336977, Train accuracy: 0.912444, val accuracy: 0.732000\n",
      "Loss: 0.286137, Train accuracy: 0.917444, val accuracy: 0.742000\n",
      "Loss: 0.262389, Train accuracy: 0.920667, val accuracy: 0.746000\n",
      "Loss: 0.282585, Train accuracy: 0.925889, val accuracy: 0.743000\n",
      "Loss: 0.221622, Train accuracy: 0.927000, val accuracy: 0.751000\n",
      "Loss: 0.240569, Train accuracy: 0.926667, val accuracy: 0.742000\n",
      "Loss: 0.493284, Train accuracy: 0.886556, val accuracy: 0.742000\n",
      "Loss: 0.164314, Train accuracy: 0.900444, val accuracy: 0.722000\n",
      "Loss: 0.302511, Train accuracy: 0.886111, val accuracy: 0.714000\n",
      "Loss: 0.453358, Train accuracy: 0.882889, val accuracy: 0.717000\n",
      "Loss: 0.274290, Train accuracy: 0.936778, val accuracy: 0.749000\n",
      "Loss: 0.286037, Train accuracy: 0.942000, val accuracy: 0.747000\n",
      "Loss: 0.386116, Train accuracy: 0.929889, val accuracy: 0.752000\n",
      "Loss: 0.451235, Train accuracy: 0.880889, val accuracy: 0.725000\n",
      "Loss: 0.100448, Train accuracy: 0.933222, val accuracy: 0.743000\n",
      "Loss: 0.332597, Train accuracy: 0.918333, val accuracy: 0.750000\n",
      "Loss: 0.241663, Train accuracy: 0.926444, val accuracy: 0.741000\n",
      "Loss: 0.237910, Train accuracy: 0.947778, val accuracy: 0.748000\n",
      "Loss: 0.164991, Train accuracy: 0.920000, val accuracy: 0.731000\n",
      "Loss: 0.177853, Train accuracy: 0.940556, val accuracy: 0.742000\n",
      "Loss: 0.293602, Train accuracy: 0.933667, val accuracy: 0.746000\n",
      "Loss: 0.256985, Train accuracy: 0.936111, val accuracy: 0.748000\n",
      "Loss: 0.199763, Train accuracy: 0.948667, val accuracy: 0.746000\n",
      "Loss: 0.166423, Train accuracy: 0.954444, val accuracy: 0.748000\n",
      "Loss: 0.309609, Train accuracy: 0.912444, val accuracy: 0.734000\n",
      "Loss: 0.180046, Train accuracy: 0.958333, val accuracy: 0.749000\n",
      "Loss: 0.228488, Train accuracy: 0.950222, val accuracy: 0.760000\n",
      "Loss: 0.260284, Train accuracy: 0.932667, val accuracy: 0.733000\n",
      "Loss: 0.236825, Train accuracy: 0.947222, val accuracy: 0.744000\n",
      "Loss: 0.263695, Train accuracy: 0.891111, val accuracy: 0.719000\n",
      "best val acc = 0.76, epoch_n=96\n",
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=128 batch_size=64\n",
      "Loss: 2.240812, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230255, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.079554, Train accuracy: 0.232111, val accuracy: 0.237000\n",
      "Loss: 2.152238, Train accuracy: 0.279333, val accuracy: 0.280000\n",
      "Loss: 1.916439, Train accuracy: 0.338111, val accuracy: 0.335000\n",
      "Loss: 1.707705, Train accuracy: 0.394556, val accuracy: 0.388000\n",
      "Loss: 1.527051, Train accuracy: 0.508333, val accuracy: 0.501000\n",
      "Loss: 1.293556, Train accuracy: 0.550333, val accuracy: 0.537000\n",
      "Loss: 1.464674, Train accuracy: 0.612889, val accuracy: 0.598000\n",
      "Loss: 1.459930, Train accuracy: 0.648444, val accuracy: 0.636000\n",
      "Loss: 1.004088, Train accuracy: 0.649667, val accuracy: 0.644000\n",
      "Loss: 1.520566, Train accuracy: 0.663333, val accuracy: 0.643000\n",
      "Loss: 1.273727, Train accuracy: 0.664333, val accuracy: 0.651000\n",
      "Loss: 0.724862, Train accuracy: 0.703333, val accuracy: 0.690000\n",
      "Loss: 1.024671, Train accuracy: 0.720222, val accuracy: 0.680000\n",
      "Loss: 0.700425, Train accuracy: 0.734556, val accuracy: 0.702000\n",
      "Loss: 0.905419, Train accuracy: 0.732333, val accuracy: 0.696000\n",
      "Loss: 0.878702, Train accuracy: 0.750111, val accuracy: 0.714000\n",
      "Loss: 0.633726, Train accuracy: 0.741889, val accuracy: 0.699000\n",
      "Loss: 1.288634, Train accuracy: 0.753889, val accuracy: 0.724000\n",
      "Loss: 0.781318, Train accuracy: 0.750889, val accuracy: 0.708000\n",
      "Loss: 1.033753, Train accuracy: 0.788556, val accuracy: 0.728000\n",
      "Loss: 1.149881, Train accuracy: 0.777667, val accuracy: 0.715000\n",
      "Loss: 0.804654, Train accuracy: 0.802667, val accuracy: 0.723000\n",
      "Loss: 0.713516, Train accuracy: 0.800556, val accuracy: 0.723000\n",
      "Loss: 0.343207, Train accuracy: 0.818778, val accuracy: 0.734000\n",
      "Loss: 0.600202, Train accuracy: 0.809556, val accuracy: 0.728000\n",
      "Loss: 0.819847, Train accuracy: 0.782889, val accuracy: 0.700000\n",
      "Loss: 0.615050, Train accuracy: 0.821222, val accuracy: 0.743000\n",
      "Loss: 0.743517, Train accuracy: 0.827333, val accuracy: 0.742000\n",
      "Loss: 0.556679, Train accuracy: 0.831333, val accuracy: 0.726000\n",
      "Loss: 0.455193, Train accuracy: 0.838222, val accuracy: 0.734000\n",
      "Loss: 0.428724, Train accuracy: 0.828889, val accuracy: 0.713000\n",
      "Loss: 0.457926, Train accuracy: 0.851111, val accuracy: 0.749000\n",
      "Loss: 0.609450, Train accuracy: 0.803333, val accuracy: 0.714000\n",
      "Loss: 0.389964, Train accuracy: 0.860778, val accuracy: 0.739000\n",
      "Loss: 0.530675, Train accuracy: 0.844444, val accuracy: 0.743000\n",
      "Loss: 0.447113, Train accuracy: 0.870111, val accuracy: 0.756000\n",
      "Loss: 0.253813, Train accuracy: 0.849667, val accuracy: 0.723000\n",
      "Loss: 0.518523, Train accuracy: 0.833000, val accuracy: 0.730000\n",
      "Loss: 0.555941, Train accuracy: 0.862667, val accuracy: 0.735000\n",
      "Loss: 0.516389, Train accuracy: 0.867000, val accuracy: 0.731000\n",
      "Loss: 0.392699, Train accuracy: 0.865333, val accuracy: 0.726000\n",
      "Loss: 0.594788, Train accuracy: 0.875889, val accuracy: 0.747000\n",
      "Loss: 0.404105, Train accuracy: 0.889000, val accuracy: 0.751000\n",
      "Loss: 0.274678, Train accuracy: 0.897444, val accuracy: 0.751000\n",
      "Loss: 0.250643, Train accuracy: 0.896667, val accuracy: 0.742000\n",
      "Loss: 0.432605, Train accuracy: 0.866556, val accuracy: 0.724000\n",
      "Loss: 0.474481, Train accuracy: 0.846333, val accuracy: 0.708000\n",
      "Loss: 0.387077, Train accuracy: 0.892889, val accuracy: 0.744000\n",
      "Loss: 0.212800, Train accuracy: 0.894667, val accuracy: 0.749000\n",
      "Loss: 0.166312, Train accuracy: 0.904778, val accuracy: 0.758000\n",
      "Loss: 0.500718, Train accuracy: 0.884667, val accuracy: 0.739000\n",
      "Loss: 0.298365, Train accuracy: 0.920444, val accuracy: 0.759000\n",
      "Loss: 0.432326, Train accuracy: 0.872556, val accuracy: 0.720000\n",
      "Loss: 0.210982, Train accuracy: 0.913222, val accuracy: 0.745000\n",
      "Loss: 0.306290, Train accuracy: 0.905889, val accuracy: 0.749000\n",
      "Loss: 0.281348, Train accuracy: 0.931111, val accuracy: 0.764000\n",
      "Loss: 0.317037, Train accuracy: 0.923222, val accuracy: 0.749000\n",
      "Loss: 0.225661, Train accuracy: 0.920667, val accuracy: 0.749000\n",
      "Loss: 0.155199, Train accuracy: 0.930667, val accuracy: 0.755000\n",
      "Loss: 0.357789, Train accuracy: 0.893889, val accuracy: 0.741000\n",
      "Loss: 0.133469, Train accuracy: 0.935111, val accuracy: 0.755000\n",
      "Loss: 0.365695, Train accuracy: 0.872778, val accuracy: 0.731000\n",
      "Loss: 0.262494, Train accuracy: 0.938000, val accuracy: 0.750000\n",
      "Loss: 0.640633, Train accuracy: 0.842556, val accuracy: 0.697000\n",
      "Loss: 0.234233, Train accuracy: 0.943333, val accuracy: 0.751000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.288921, Train accuracy: 0.944000, val accuracy: 0.759000\n",
      "Loss: 0.195964, Train accuracy: 0.941000, val accuracy: 0.754000\n",
      "Loss: 0.138970, Train accuracy: 0.955000, val accuracy: 0.755000\n",
      "Loss: 0.128924, Train accuracy: 0.954444, val accuracy: 0.760000\n",
      "Loss: 0.329293, Train accuracy: 0.914778, val accuracy: 0.743000\n",
      "Loss: 0.194800, Train accuracy: 0.942889, val accuracy: 0.753000\n",
      "Loss: 0.242936, Train accuracy: 0.932889, val accuracy: 0.727000\n",
      "Loss: 0.115143, Train accuracy: 0.942556, val accuracy: 0.732000\n",
      "Loss: 0.335316, Train accuracy: 0.930000, val accuracy: 0.743000\n",
      "Loss: 0.240616, Train accuracy: 0.961222, val accuracy: 0.757000\n",
      "Loss: 0.465084, Train accuracy: 0.928000, val accuracy: 0.752000\n",
      "Loss: 0.222476, Train accuracy: 0.953444, val accuracy: 0.756000\n",
      "Loss: 0.167733, Train accuracy: 0.950667, val accuracy: 0.755000\n",
      "Loss: 0.145027, Train accuracy: 0.958000, val accuracy: 0.760000\n",
      "Loss: 0.043436, Train accuracy: 0.962111, val accuracy: 0.762000\n",
      "Loss: 0.112048, Train accuracy: 0.964000, val accuracy: 0.754000\n",
      "Loss: 0.162104, Train accuracy: 0.970444, val accuracy: 0.759000\n",
      "Loss: 0.258058, Train accuracy: 0.957667, val accuracy: 0.743000\n",
      "Loss: 0.289076, Train accuracy: 0.952778, val accuracy: 0.758000\n",
      "Loss: 0.250565, Train accuracy: 0.950778, val accuracy: 0.753000\n",
      "Loss: 0.102302, Train accuracy: 0.957556, val accuracy: 0.745000\n",
      "Loss: 0.187716, Train accuracy: 0.957556, val accuracy: 0.756000\n",
      "Loss: 0.133117, Train accuracy: 0.950889, val accuracy: 0.744000\n",
      "Loss: 0.129172, Train accuracy: 0.971000, val accuracy: 0.758000\n",
      "Loss: 0.176053, Train accuracy: 0.970000, val accuracy: 0.752000\n",
      "Loss: 0.142861, Train accuracy: 0.971889, val accuracy: 0.750000\n",
      "Loss: 0.073458, Train accuracy: 0.974667, val accuracy: 0.757000\n",
      "Loss: 0.119740, Train accuracy: 0.970000, val accuracy: 0.762000\n",
      "Loss: 0.222507, Train accuracy: 0.956333, val accuracy: 0.746000\n",
      "Loss: 0.103628, Train accuracy: 0.968778, val accuracy: 0.752000\n",
      "Loss: 0.146976, Train accuracy: 0.956333, val accuracy: 0.748000\n",
      "Loss: 0.099391, Train accuracy: 0.982778, val accuracy: 0.756000\n",
      "Loss: 0.788024, Train accuracy: 0.840444, val accuracy: 0.700000\n",
      "best val acc = 0.764, epoch_n=57\n",
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=128 batch_size=50\n",
      "Loss: 2.301665, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233993, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204106, Train accuracy: 0.276889, val accuracy: 0.283000\n",
      "Loss: 1.721003, Train accuracy: 0.366444, val accuracy: 0.372000\n",
      "Loss: 1.452070, Train accuracy: 0.449444, val accuracy: 0.441000\n",
      "Loss: 1.487227, Train accuracy: 0.546667, val accuracy: 0.549000\n",
      "Loss: 1.344498, Train accuracy: 0.611778, val accuracy: 0.602000\n",
      "Loss: 1.165525, Train accuracy: 0.630222, val accuracy: 0.619000\n",
      "Loss: 1.148161, Train accuracy: 0.662111, val accuracy: 0.648000\n",
      "Loss: 1.416911, Train accuracy: 0.648444, val accuracy: 0.642000\n",
      "Loss: 0.896805, Train accuracy: 0.716444, val accuracy: 0.695000\n",
      "Loss: 0.726620, Train accuracy: 0.719000, val accuracy: 0.679000\n",
      "Loss: 0.913631, Train accuracy: 0.732556, val accuracy: 0.705000\n",
      "Loss: 0.577643, Train accuracy: 0.725556, val accuracy: 0.691000\n",
      "Loss: 0.686053, Train accuracy: 0.743111, val accuracy: 0.703000\n",
      "Loss: 0.843222, Train accuracy: 0.742556, val accuracy: 0.699000\n",
      "Loss: 0.669282, Train accuracy: 0.773556, val accuracy: 0.723000\n",
      "Loss: 0.572606, Train accuracy: 0.785222, val accuracy: 0.714000\n",
      "Loss: 0.666280, Train accuracy: 0.796556, val accuracy: 0.727000\n",
      "Loss: 0.761913, Train accuracy: 0.799000, val accuracy: 0.721000\n",
      "Loss: 0.715356, Train accuracy: 0.806778, val accuracy: 0.731000\n",
      "Loss: 0.646202, Train accuracy: 0.825333, val accuracy: 0.737000\n",
      "Loss: 0.648027, Train accuracy: 0.810667, val accuracy: 0.724000\n",
      "Loss: 0.879289, Train accuracy: 0.822333, val accuracy: 0.721000\n",
      "Loss: 0.670109, Train accuracy: 0.822556, val accuracy: 0.723000\n",
      "Loss: 0.438529, Train accuracy: 0.839333, val accuracy: 0.726000\n",
      "Loss: 0.670636, Train accuracy: 0.842778, val accuracy: 0.738000\n",
      "Loss: 0.462393, Train accuracy: 0.840222, val accuracy: 0.722000\n",
      "Loss: 0.787155, Train accuracy: 0.834778, val accuracy: 0.721000\n",
      "Loss: 0.465679, Train accuracy: 0.859889, val accuracy: 0.742000\n",
      "Loss: 0.232051, Train accuracy: 0.875667, val accuracy: 0.743000\n",
      "Loss: 0.322411, Train accuracy: 0.863222, val accuracy: 0.740000\n",
      "Loss: 0.340183, Train accuracy: 0.884222, val accuracy: 0.747000\n",
      "Loss: 0.435999, Train accuracy: 0.882667, val accuracy: 0.752000\n",
      "Loss: 0.441039, Train accuracy: 0.869444, val accuracy: 0.741000\n",
      "Loss: 0.431755, Train accuracy: 0.894444, val accuracy: 0.757000\n",
      "Loss: 0.293690, Train accuracy: 0.900667, val accuracy: 0.755000\n",
      "Loss: 0.285047, Train accuracy: 0.905111, val accuracy: 0.757000\n",
      "Loss: 0.292302, Train accuracy: 0.897778, val accuracy: 0.745000\n",
      "Loss: 0.409062, Train accuracy: 0.890556, val accuracy: 0.744000\n",
      "Loss: 0.245918, Train accuracy: 0.906333, val accuracy: 0.753000\n",
      "Loss: 0.240425, Train accuracy: 0.900111, val accuracy: 0.742000\n",
      "Loss: 0.376917, Train accuracy: 0.916444, val accuracy: 0.754000\n",
      "Loss: 0.369317, Train accuracy: 0.879000, val accuracy: 0.721000\n",
      "Loss: 0.190418, Train accuracy: 0.912889, val accuracy: 0.757000\n",
      "Loss: 0.317201, Train accuracy: 0.912667, val accuracy: 0.746000\n",
      "Loss: 0.476561, Train accuracy: 0.897333, val accuracy: 0.738000\n",
      "Loss: 0.356380, Train accuracy: 0.913889, val accuracy: 0.766000\n",
      "Loss: 0.381391, Train accuracy: 0.928111, val accuracy: 0.756000\n",
      "Loss: 0.424961, Train accuracy: 0.932667, val accuracy: 0.759000\n",
      "Loss: 0.244821, Train accuracy: 0.935111, val accuracy: 0.767000\n",
      "Loss: 0.273985, Train accuracy: 0.923111, val accuracy: 0.749000\n",
      "Loss: 0.275404, Train accuracy: 0.899222, val accuracy: 0.729000\n",
      "Loss: 0.343071, Train accuracy: 0.925889, val accuracy: 0.755000\n",
      "Loss: 0.126667, Train accuracy: 0.945778, val accuracy: 0.770000\n",
      "Loss: 0.169957, Train accuracy: 0.941000, val accuracy: 0.759000\n",
      "Loss: 0.247984, Train accuracy: 0.948000, val accuracy: 0.761000\n",
      "Loss: 0.275647, Train accuracy: 0.945778, val accuracy: 0.772000\n",
      "Loss: 0.283625, Train accuracy: 0.946111, val accuracy: 0.759000\n",
      "Loss: 0.102705, Train accuracy: 0.946222, val accuracy: 0.766000\n",
      "Loss: 0.254072, Train accuracy: 0.958333, val accuracy: 0.768000\n",
      "Loss: 0.219967, Train accuracy: 0.950556, val accuracy: 0.756000\n",
      "Loss: 0.108100, Train accuracy: 0.948444, val accuracy: 0.759000\n",
      "Loss: 0.284569, Train accuracy: 0.955111, val accuracy: 0.758000\n",
      "Loss: 0.313527, Train accuracy: 0.945111, val accuracy: 0.742000\n",
      "Loss: 0.184129, Train accuracy: 0.952889, val accuracy: 0.763000\n",
      "Loss: 0.194006, Train accuracy: 0.960444, val accuracy: 0.763000\n",
      "Loss: 0.239841, Train accuracy: 0.960778, val accuracy: 0.771000\n",
      "Loss: 0.279912, Train accuracy: 0.946000, val accuracy: 0.754000\n",
      "Loss: 0.112472, Train accuracy: 0.965111, val accuracy: 0.765000\n",
      "Loss: 0.133354, Train accuracy: 0.951667, val accuracy: 0.756000\n",
      "Loss: 0.207173, Train accuracy: 0.948333, val accuracy: 0.737000\n",
      "Loss: 0.138934, Train accuracy: 0.959111, val accuracy: 0.752000\n",
      "Loss: 0.207833, Train accuracy: 0.966111, val accuracy: 0.762000\n",
      "Loss: 0.156330, Train accuracy: 0.967222, val accuracy: 0.758000\n",
      "Loss: 0.186612, Train accuracy: 0.963778, val accuracy: 0.757000\n",
      "Loss: 0.133384, Train accuracy: 0.964667, val accuracy: 0.759000\n",
      "Loss: 0.388346, Train accuracy: 0.949667, val accuracy: 0.748000\n",
      "Loss: 0.179158, Train accuracy: 0.948000, val accuracy: 0.747000\n",
      "Loss: 0.170361, Train accuracy: 0.976889, val accuracy: 0.767000\n",
      "Loss: 0.133947, Train accuracy: 0.972333, val accuracy: 0.763000\n",
      "Loss: 0.082155, Train accuracy: 0.966333, val accuracy: 0.760000\n",
      "Loss: 0.140373, Train accuracy: 0.980000, val accuracy: 0.771000\n",
      "Loss: 0.097987, Train accuracy: 0.975111, val accuracy: 0.759000\n",
      "Loss: 0.183127, Train accuracy: 0.971667, val accuracy: 0.759000\n",
      "Loss: 0.425919, Train accuracy: 0.966000, val accuracy: 0.755000\n",
      "Loss: 0.224857, Train accuracy: 0.972444, val accuracy: 0.757000\n",
      "Loss: 0.105486, Train accuracy: 0.982333, val accuracy: 0.767000\n",
      "Loss: 0.073114, Train accuracy: 0.986778, val accuracy: 0.774000\n",
      "Loss: 0.140307, Train accuracy: 0.977556, val accuracy: 0.766000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.213440, Train accuracy: 0.977556, val accuracy: 0.759000\n",
      "Loss: 0.071329, Train accuracy: 0.978889, val accuracy: 0.766000\n",
      "Loss: 0.110609, Train accuracy: 0.986444, val accuracy: 0.771000\n",
      "Loss: 0.062159, Train accuracy: 0.985444, val accuracy: 0.777000\n",
      "Loss: 0.081138, Train accuracy: 0.982333, val accuracy: 0.762000\n",
      "Loss: 0.101960, Train accuracy: 0.985444, val accuracy: 0.772000\n",
      "Loss: 0.072812, Train accuracy: 0.970889, val accuracy: 0.746000\n",
      "Loss: 0.037806, Train accuracy: 0.989333, val accuracy: 0.774000\n",
      "Loss: 0.034297, Train accuracy: 0.975111, val accuracy: 0.753000\n",
      "Loss: 0.068037, Train accuracy: 0.991444, val accuracy: 0.777000\n",
      "best val acc = 0.777, epoch_n=93\n",
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=128 batch_size=80\n",
      "Loss: 2.273287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319803, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.164126, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209226, Train accuracy: 0.242222, val accuracy: 0.244000\n",
      "Loss: 2.045148, Train accuracy: 0.264444, val accuracy: 0.270000\n",
      "Loss: 1.645456, Train accuracy: 0.360556, val accuracy: 0.363000\n",
      "Loss: 1.878350, Train accuracy: 0.425000, val accuracy: 0.429000\n",
      "Loss: 1.580443, Train accuracy: 0.478444, val accuracy: 0.463000\n",
      "Loss: 1.456983, Train accuracy: 0.502000, val accuracy: 0.512000\n",
      "Loss: 1.414627, Train accuracy: 0.585444, val accuracy: 0.576000\n",
      "Loss: 1.466248, Train accuracy: 0.615333, val accuracy: 0.595000\n",
      "Loss: 1.249316, Train accuracy: 0.609111, val accuracy: 0.598000\n",
      "Loss: 1.336637, Train accuracy: 0.627556, val accuracy: 0.609000\n",
      "Loss: 0.897972, Train accuracy: 0.681889, val accuracy: 0.654000\n",
      "Loss: 1.262131, Train accuracy: 0.668889, val accuracy: 0.658000\n",
      "Loss: 1.030910, Train accuracy: 0.703444, val accuracy: 0.679000\n",
      "Loss: 1.126968, Train accuracy: 0.712000, val accuracy: 0.688000\n",
      "Loss: 0.848751, Train accuracy: 0.706000, val accuracy: 0.685000\n",
      "Loss: 0.890527, Train accuracy: 0.718889, val accuracy: 0.685000\n",
      "Loss: 1.001735, Train accuracy: 0.682778, val accuracy: 0.659000\n",
      "Loss: 0.703901, Train accuracy: 0.740333, val accuracy: 0.710000\n",
      "Loss: 0.528047, Train accuracy: 0.758889, val accuracy: 0.705000\n",
      "Loss: 1.116521, Train accuracy: 0.760000, val accuracy: 0.694000\n",
      "Loss: 0.558969, Train accuracy: 0.748556, val accuracy: 0.712000\n",
      "Loss: 0.794270, Train accuracy: 0.775556, val accuracy: 0.730000\n",
      "Loss: 0.691251, Train accuracy: 0.714333, val accuracy: 0.677000\n",
      "Loss: 0.650329, Train accuracy: 0.781778, val accuracy: 0.721000\n",
      "Loss: 0.811613, Train accuracy: 0.776778, val accuracy: 0.706000\n",
      "Loss: 0.561262, Train accuracy: 0.775667, val accuracy: 0.715000\n",
      "Loss: 0.389635, Train accuracy: 0.813111, val accuracy: 0.730000\n",
      "Loss: 0.516802, Train accuracy: 0.790333, val accuracy: 0.731000\n",
      "Loss: 0.595394, Train accuracy: 0.810111, val accuracy: 0.724000\n",
      "Loss: 0.608238, Train accuracy: 0.815778, val accuracy: 0.740000\n",
      "Loss: 0.447446, Train accuracy: 0.809778, val accuracy: 0.727000\n",
      "Loss: 0.459107, Train accuracy: 0.813889, val accuracy: 0.716000\n",
      "Loss: 0.608521, Train accuracy: 0.822000, val accuracy: 0.713000\n",
      "Loss: 0.590748, Train accuracy: 0.804333, val accuracy: 0.706000\n",
      "Loss: 0.790796, Train accuracy: 0.827222, val accuracy: 0.731000\n",
      "Loss: 0.294803, Train accuracy: 0.844444, val accuracy: 0.741000\n",
      "Loss: 0.731898, Train accuracy: 0.819556, val accuracy: 0.732000\n",
      "Loss: 0.482943, Train accuracy: 0.844778, val accuracy: 0.754000\n",
      "Loss: 0.424908, Train accuracy: 0.869889, val accuracy: 0.741000\n",
      "Loss: 0.721447, Train accuracy: 0.783889, val accuracy: 0.667000\n",
      "Loss: 0.250274, Train accuracy: 0.865889, val accuracy: 0.740000\n",
      "Loss: 0.440320, Train accuracy: 0.829444, val accuracy: 0.725000\n",
      "Loss: 0.381846, Train accuracy: 0.856889, val accuracy: 0.741000\n",
      "Loss: 0.666758, Train accuracy: 0.828444, val accuracy: 0.707000\n",
      "Loss: 0.534719, Train accuracy: 0.859889, val accuracy: 0.741000\n",
      "Loss: 0.421730, Train accuracy: 0.874333, val accuracy: 0.753000\n",
      "Loss: 0.387901, Train accuracy: 0.881222, val accuracy: 0.763000\n",
      "Loss: 0.483882, Train accuracy: 0.858111, val accuracy: 0.731000\n",
      "Loss: 0.421411, Train accuracy: 0.820667, val accuracy: 0.708000\n",
      "Loss: 0.228066, Train accuracy: 0.879556, val accuracy: 0.736000\n",
      "Loss: 0.285553, Train accuracy: 0.893111, val accuracy: 0.741000\n",
      "Loss: 0.529083, Train accuracy: 0.895444, val accuracy: 0.744000\n",
      "Loss: 0.431207, Train accuracy: 0.883444, val accuracy: 0.750000\n",
      "Loss: 0.165610, Train accuracy: 0.913778, val accuracy: 0.761000\n",
      "Loss: 0.254667, Train accuracy: 0.884000, val accuracy: 0.749000\n",
      "Loss: 0.674876, Train accuracy: 0.862667, val accuracy: 0.733000\n",
      "Loss: 0.471282, Train accuracy: 0.885889, val accuracy: 0.744000\n",
      "Loss: 0.457973, Train accuracy: 0.886778, val accuracy: 0.744000\n",
      "Loss: 0.187603, Train accuracy: 0.924222, val accuracy: 0.754000\n",
      "Loss: 0.299376, Train accuracy: 0.916889, val accuracy: 0.753000\n",
      "Loss: 0.477404, Train accuracy: 0.882778, val accuracy: 0.747000\n",
      "Loss: 0.658374, Train accuracy: 0.882778, val accuracy: 0.754000\n",
      "Loss: 0.290346, Train accuracy: 0.920667, val accuracy: 0.745000\n",
      "Loss: 0.312974, Train accuracy: 0.921778, val accuracy: 0.764000\n",
      "Loss: 0.266717, Train accuracy: 0.931889, val accuracy: 0.769000\n",
      "Loss: 0.228544, Train accuracy: 0.927222, val accuracy: 0.759000\n",
      "Loss: 0.298138, Train accuracy: 0.909222, val accuracy: 0.746000\n",
      "Loss: 0.237105, Train accuracy: 0.918333, val accuracy: 0.761000\n",
      "Loss: 0.141898, Train accuracy: 0.936222, val accuracy: 0.771000\n",
      "Loss: 0.280937, Train accuracy: 0.926889, val accuracy: 0.758000\n",
      "Loss: 0.276078, Train accuracy: 0.940889, val accuracy: 0.764000\n",
      "Loss: 0.184696, Train accuracy: 0.943889, val accuracy: 0.775000\n",
      "Loss: 0.281811, Train accuracy: 0.930667, val accuracy: 0.757000\n",
      "Loss: 0.260722, Train accuracy: 0.913889, val accuracy: 0.757000\n",
      "Loss: 0.209157, Train accuracy: 0.935667, val accuracy: 0.753000\n",
      "Loss: 0.210372, Train accuracy: 0.931556, val accuracy: 0.761000\n",
      "Loss: 0.206341, Train accuracy: 0.926778, val accuracy: 0.751000\n",
      "Loss: 0.211326, Train accuracy: 0.948000, val accuracy: 0.772000\n",
      "Loss: 0.395931, Train accuracy: 0.884111, val accuracy: 0.721000\n",
      "Loss: 0.070952, Train accuracy: 0.957889, val accuracy: 0.776000\n",
      "Loss: 0.188225, Train accuracy: 0.929556, val accuracy: 0.751000\n",
      "Loss: 0.361169, Train accuracy: 0.943667, val accuracy: 0.762000\n",
      "Loss: 0.241284, Train accuracy: 0.923667, val accuracy: 0.744000\n",
      "Loss: 0.121727, Train accuracy: 0.952889, val accuracy: 0.760000\n",
      "Loss: 0.257283, Train accuracy: 0.945889, val accuracy: 0.766000\n",
      "Loss: 0.241981, Train accuracy: 0.942778, val accuracy: 0.758000\n",
      "Loss: 0.256556, Train accuracy: 0.940667, val accuracy: 0.764000\n",
      "Loss: 0.112057, Train accuracy: 0.966333, val accuracy: 0.772000\n",
      "Loss: 0.233404, Train accuracy: 0.955000, val accuracy: 0.757000\n",
      "Loss: 0.231506, Train accuracy: 0.889222, val accuracy: 0.731000\n",
      "Loss: 0.260170, Train accuracy: 0.953778, val accuracy: 0.757000\n",
      "Loss: 0.202471, Train accuracy: 0.959444, val accuracy: 0.757000\n",
      "Loss: 0.334986, Train accuracy: 0.927778, val accuracy: 0.742000\n",
      "Loss: 0.189981, Train accuracy: 0.964444, val accuracy: 0.778000\n",
      "Loss: 0.070341, Train accuracy: 0.967444, val accuracy: 0.756000\n",
      "Loss: 0.237484, Train accuracy: 0.928444, val accuracy: 0.739000\n",
      "Loss: 0.077525, Train accuracy: 0.976111, val accuracy: 0.765000\n",
      "best val acc = 0.778, epoch_n=96\n",
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=175 batch_size=64\n",
      "Loss: 2.255145, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236779, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.032548, Train accuracy: 0.220778, val accuracy: 0.226000\n",
      "Loss: 1.851001, Train accuracy: 0.271444, val accuracy: 0.267000\n",
      "Loss: 1.868790, Train accuracy: 0.367333, val accuracy: 0.374000\n",
      "Loss: 1.409104, Train accuracy: 0.466111, val accuracy: 0.449000\n",
      "Loss: 1.683044, Train accuracy: 0.536778, val accuracy: 0.535000\n",
      "Loss: 1.277864, Train accuracy: 0.586667, val accuracy: 0.579000\n",
      "Loss: 1.291910, Train accuracy: 0.629778, val accuracy: 0.606000\n",
      "Loss: 1.056503, Train accuracy: 0.645444, val accuracy: 0.637000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.922986, Train accuracy: 0.678667, val accuracy: 0.669000\n",
      "Loss: 1.108164, Train accuracy: 0.661556, val accuracy: 0.650000\n",
      "Loss: 1.240351, Train accuracy: 0.695111, val accuracy: 0.685000\n",
      "Loss: 1.115514, Train accuracy: 0.708556, val accuracy: 0.699000\n",
      "Loss: 0.774619, Train accuracy: 0.697889, val accuracy: 0.679000\n",
      "Loss: 0.870556, Train accuracy: 0.735000, val accuracy: 0.702000\n",
      "Loss: 0.630485, Train accuracy: 0.747889, val accuracy: 0.720000\n",
      "Loss: 0.667210, Train accuracy: 0.755333, val accuracy: 0.720000\n",
      "Loss: 0.828156, Train accuracy: 0.763222, val accuracy: 0.713000\n",
      "Loss: 0.718062, Train accuracy: 0.775778, val accuracy: 0.730000\n",
      "Loss: 1.227559, Train accuracy: 0.729111, val accuracy: 0.688000\n",
      "Loss: 0.450150, Train accuracy: 0.769444, val accuracy: 0.694000\n",
      "Loss: 0.859962, Train accuracy: 0.746778, val accuracy: 0.698000\n",
      "Loss: 0.642114, Train accuracy: 0.802556, val accuracy: 0.731000\n",
      "Loss: 0.845864, Train accuracy: 0.796889, val accuracy: 0.726000\n",
      "Loss: 0.898226, Train accuracy: 0.764333, val accuracy: 0.691000\n",
      "Loss: 0.368143, Train accuracy: 0.788111, val accuracy: 0.706000\n",
      "Loss: 0.654473, Train accuracy: 0.795222, val accuracy: 0.709000\n",
      "Loss: 0.471614, Train accuracy: 0.828000, val accuracy: 0.739000\n",
      "Loss: 0.677946, Train accuracy: 0.832778, val accuracy: 0.741000\n",
      "Loss: 0.642779, Train accuracy: 0.800667, val accuracy: 0.698000\n",
      "Loss: 0.326134, Train accuracy: 0.810333, val accuracy: 0.701000\n",
      "Loss: 0.453774, Train accuracy: 0.858556, val accuracy: 0.744000\n",
      "Loss: 0.734253, Train accuracy: 0.832444, val accuracy: 0.731000\n",
      "Loss: 0.638064, Train accuracy: 0.858222, val accuracy: 0.749000\n",
      "Loss: 0.523796, Train accuracy: 0.867889, val accuracy: 0.738000\n",
      "Loss: 0.594623, Train accuracy: 0.863222, val accuracy: 0.741000\n",
      "Loss: 0.446248, Train accuracy: 0.877667, val accuracy: 0.748000\n",
      "Loss: 0.442735, Train accuracy: 0.884667, val accuracy: 0.753000\n",
      "Loss: 0.384872, Train accuracy: 0.888778, val accuracy: 0.755000\n",
      "Loss: 0.494380, Train accuracy: 0.864667, val accuracy: 0.742000\n",
      "Loss: 0.455011, Train accuracy: 0.877444, val accuracy: 0.748000\n",
      "Loss: 0.144503, Train accuracy: 0.890111, val accuracy: 0.752000\n",
      "Loss: 0.265365, Train accuracy: 0.879333, val accuracy: 0.734000\n",
      "Loss: 0.422932, Train accuracy: 0.899111, val accuracy: 0.752000\n",
      "Loss: 0.213066, Train accuracy: 0.900667, val accuracy: 0.742000\n",
      "Loss: 0.503603, Train accuracy: 0.811556, val accuracy: 0.689000\n",
      "Loss: 0.431122, Train accuracy: 0.924667, val accuracy: 0.762000\n",
      "Loss: 0.493421, Train accuracy: 0.912444, val accuracy: 0.750000\n",
      "Loss: 0.296416, Train accuracy: 0.907222, val accuracy: 0.747000\n",
      "Loss: 0.475088, Train accuracy: 0.899222, val accuracy: 0.743000\n",
      "Loss: 0.284786, Train accuracy: 0.912778, val accuracy: 0.742000\n",
      "Loss: 0.402031, Train accuracy: 0.859444, val accuracy: 0.707000\n",
      "Loss: 0.607593, Train accuracy: 0.799222, val accuracy: 0.687000\n",
      "Loss: 0.164560, Train accuracy: 0.931333, val accuracy: 0.754000\n",
      "Loss: 0.581876, Train accuracy: 0.913778, val accuracy: 0.744000\n",
      "Loss: 0.227714, Train accuracy: 0.940333, val accuracy: 0.748000\n",
      "Loss: 0.301573, Train accuracy: 0.919111, val accuracy: 0.742000\n",
      "Loss: 0.209235, Train accuracy: 0.923556, val accuracy: 0.749000\n",
      "Loss: 0.123866, Train accuracy: 0.944667, val accuracy: 0.759000\n",
      "Loss: 0.269257, Train accuracy: 0.931111, val accuracy: 0.746000\n",
      "Loss: 0.195040, Train accuracy: 0.953111, val accuracy: 0.761000\n",
      "Loss: 0.206276, Train accuracy: 0.919111, val accuracy: 0.739000\n",
      "Loss: 0.250492, Train accuracy: 0.950000, val accuracy: 0.767000\n",
      "Loss: 0.267829, Train accuracy: 0.953889, val accuracy: 0.760000\n",
      "Loss: 0.419615, Train accuracy: 0.873778, val accuracy: 0.726000\n",
      "Loss: 0.221987, Train accuracy: 0.947111, val accuracy: 0.761000\n",
      "Loss: 0.213664, Train accuracy: 0.951333, val accuracy: 0.753000\n",
      "Loss: 0.138492, Train accuracy: 0.948333, val accuracy: 0.757000\n",
      "Loss: 0.220153, Train accuracy: 0.951778, val accuracy: 0.758000\n",
      "Loss: 0.091835, Train accuracy: 0.962000, val accuracy: 0.761000\n",
      "Loss: 0.163379, Train accuracy: 0.953111, val accuracy: 0.756000\n",
      "Loss: 0.145119, Train accuracy: 0.964000, val accuracy: 0.769000\n",
      "Loss: 0.268146, Train accuracy: 0.943000, val accuracy: 0.751000\n",
      "Loss: 0.249151, Train accuracy: 0.923889, val accuracy: 0.743000\n",
      "Loss: 0.214717, Train accuracy: 0.964333, val accuracy: 0.767000\n",
      "Loss: 0.201983, Train accuracy: 0.925444, val accuracy: 0.742000\n",
      "Loss: 0.190763, Train accuracy: 0.942778, val accuracy: 0.746000\n",
      "Loss: 0.176480, Train accuracy: 0.955778, val accuracy: 0.751000\n",
      "Loss: 0.114282, Train accuracy: 0.965444, val accuracy: 0.762000\n",
      "Loss: 0.164220, Train accuracy: 0.969667, val accuracy: 0.768000\n",
      "Loss: 0.041690, Train accuracy: 0.973556, val accuracy: 0.767000\n",
      "Loss: 0.087148, Train accuracy: 0.974000, val accuracy: 0.768000\n",
      "Loss: 0.095236, Train accuracy: 0.975000, val accuracy: 0.760000\n",
      "Loss: 0.125017, Train accuracy: 0.976444, val accuracy: 0.763000\n",
      "Loss: 0.180844, Train accuracy: 0.973889, val accuracy: 0.757000\n",
      "Loss: 0.148311, Train accuracy: 0.960333, val accuracy: 0.753000\n",
      "Loss: 0.092335, Train accuracy: 0.978444, val accuracy: 0.768000\n",
      "Loss: 0.169897, Train accuracy: 0.978333, val accuracy: 0.754000\n",
      "Loss: 0.074838, Train accuracy: 0.975667, val accuracy: 0.756000\n",
      "Loss: 0.111519, Train accuracy: 0.981222, val accuracy: 0.757000\n",
      "Loss: 0.139653, Train accuracy: 0.951111, val accuracy: 0.748000\n",
      "Loss: 0.202596, Train accuracy: 0.977778, val accuracy: 0.768000\n",
      "Loss: 0.265778, Train accuracy: 0.915222, val accuracy: 0.719000\n",
      "Loss: 0.140502, Train accuracy: 0.975556, val accuracy: 0.757000\n",
      "Loss: 0.147219, Train accuracy: 0.956000, val accuracy: 0.753000\n",
      "Loss: 0.165443, Train accuracy: 0.957889, val accuracy: 0.753000\n",
      "Loss: 0.096774, Train accuracy: 0.978333, val accuracy: 0.754000\n",
      "Loss: 0.071860, Train accuracy: 0.989778, val accuracy: 0.768000\n",
      "Loss: 0.058260, Train accuracy: 0.983778, val accuracy: 0.770000\n",
      "best val acc = 0.77, epoch_n=99\n",
      "__________________________________________________________________\n",
      "learning_rate=0.1 reg_strength=1e-07 learning_rate_decay=0.999 hidden_layer_size=175 batch_size=50\n",
      "Loss: 2.181764, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.058858, Train accuracy: 0.196778, val accuracy: 0.206000\n",
      "Loss: 1.953659, Train accuracy: 0.273444, val accuracy: 0.271000\n",
      "Loss: 1.956929, Train accuracy: 0.388333, val accuracy: 0.383000\n",
      "Loss: 1.391783, Train accuracy: 0.478778, val accuracy: 0.482000\n",
      "Loss: 1.476608, Train accuracy: 0.551889, val accuracy: 0.538000\n",
      "Loss: 1.165507, Train accuracy: 0.627556, val accuracy: 0.634000\n",
      "Loss: 1.014932, Train accuracy: 0.643889, val accuracy: 0.626000\n",
      "Loss: 0.943058, Train accuracy: 0.681889, val accuracy: 0.671000\n",
      "Loss: 1.204303, Train accuracy: 0.685000, val accuracy: 0.666000\n",
      "Loss: 1.041143, Train accuracy: 0.702667, val accuracy: 0.670000\n",
      "Loss: 1.351058, Train accuracy: 0.710111, val accuracy: 0.693000\n",
      "Loss: 0.590654, Train accuracy: 0.739778, val accuracy: 0.703000\n",
      "Loss: 0.962299, Train accuracy: 0.726444, val accuracy: 0.685000\n",
      "Loss: 0.954895, Train accuracy: 0.729000, val accuracy: 0.696000\n",
      "Loss: 0.892411, Train accuracy: 0.751556, val accuracy: 0.715000\n",
      "Loss: 0.723740, Train accuracy: 0.757111, val accuracy: 0.713000\n",
      "Loss: 0.560613, Train accuracy: 0.794556, val accuracy: 0.724000\n",
      "Loss: 0.829315, Train accuracy: 0.783667, val accuracy: 0.724000\n",
      "Loss: 0.784294, Train accuracy: 0.788444, val accuracy: 0.727000\n",
      "Loss: 0.584765, Train accuracy: 0.819667, val accuracy: 0.738000\n",
      "Loss: 0.703336, Train accuracy: 0.815000, val accuracy: 0.737000\n",
      "Loss: 0.700002, Train accuracy: 0.819889, val accuracy: 0.735000\n",
      "Loss: 0.808223, Train accuracy: 0.803111, val accuracy: 0.714000\n",
      "Loss: 0.525691, Train accuracy: 0.838333, val accuracy: 0.746000\n",
      "Loss: 0.454541, Train accuracy: 0.849556, val accuracy: 0.763000\n",
      "Loss: 0.772212, Train accuracy: 0.835111, val accuracy: 0.754000\n",
      "Loss: 0.782087, Train accuracy: 0.866889, val accuracy: 0.737000\n",
      "Loss: 0.465027, Train accuracy: 0.862111, val accuracy: 0.746000\n",
      "Loss: 0.305263, Train accuracy: 0.877889, val accuracy: 0.760000\n",
      "Loss: 0.380822, Train accuracy: 0.872556, val accuracy: 0.740000\n",
      "Loss: 0.178428, Train accuracy: 0.883556, val accuracy: 0.751000\n",
      "Loss: 0.607817, Train accuracy: 0.875111, val accuracy: 0.744000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.607369, Train accuracy: 0.875444, val accuracy: 0.748000\n",
      "Loss: 0.359506, Train accuracy: 0.881444, val accuracy: 0.754000\n",
      "Loss: 0.439061, Train accuracy: 0.881889, val accuracy: 0.748000\n",
      "Loss: 0.444997, Train accuracy: 0.902222, val accuracy: 0.766000\n",
      "Loss: 0.261934, Train accuracy: 0.904889, val accuracy: 0.765000\n",
      "Loss: 0.241956, Train accuracy: 0.892778, val accuracy: 0.748000\n",
      "Loss: 0.275950, Train accuracy: 0.904000, val accuracy: 0.759000\n",
      "Loss: 0.575463, Train accuracy: 0.893333, val accuracy: 0.752000\n",
      "Loss: 0.335675, Train accuracy: 0.910889, val accuracy: 0.754000\n",
      "Loss: 0.266991, Train accuracy: 0.912333, val accuracy: 0.763000\n",
      "Loss: 0.303822, Train accuracy: 0.906778, val accuracy: 0.765000\n",
      "Loss: 0.401008, Train accuracy: 0.918556, val accuracy: 0.757000\n",
      "Loss: 0.275238, Train accuracy: 0.925667, val accuracy: 0.761000\n",
      "Loss: 0.407796, Train accuracy: 0.889778, val accuracy: 0.742000\n",
      "Loss: 0.190703, Train accuracy: 0.932333, val accuracy: 0.769000\n",
      "Loss: 0.286031, Train accuracy: 0.923667, val accuracy: 0.744000\n",
      "Loss: 0.264885, Train accuracy: 0.936444, val accuracy: 0.766000\n",
      "Loss: 0.507325, Train accuracy: 0.918778, val accuracy: 0.740000\n",
      "Loss: 0.167399, Train accuracy: 0.938556, val accuracy: 0.762000\n",
      "Loss: 0.559284, Train accuracy: 0.848556, val accuracy: 0.697000\n",
      "Loss: 0.337788, Train accuracy: 0.942889, val accuracy: 0.762000\n",
      "Loss: 0.249886, Train accuracy: 0.924111, val accuracy: 0.737000\n",
      "Loss: 0.327417, Train accuracy: 0.942556, val accuracy: 0.760000\n",
      "Loss: 0.400380, Train accuracy: 0.962222, val accuracy: 0.760000\n",
      "Loss: 0.178327, Train accuracy: 0.949778, val accuracy: 0.761000\n",
      "Loss: 0.354869, Train accuracy: 0.924111, val accuracy: 0.747000\n",
      "Loss: 0.167796, Train accuracy: 0.968000, val accuracy: 0.770000\n",
      "Loss: 0.345638, Train accuracy: 0.945000, val accuracy: 0.756000\n",
      "Loss: 0.171542, Train accuracy: 0.962222, val accuracy: 0.752000\n",
      "Loss: 0.243547, Train accuracy: 0.935222, val accuracy: 0.748000\n",
      "Loss: 0.063365, Train accuracy: 0.974333, val accuracy: 0.779000\n",
      "Loss: 0.240946, Train accuracy: 0.951778, val accuracy: 0.744000\n",
      "Loss: 0.130879, Train accuracy: 0.966222, val accuracy: 0.762000\n",
      "Loss: 0.088858, Train accuracy: 0.963333, val accuracy: 0.753000\n",
      "Loss: 0.245143, Train accuracy: 0.963222, val accuracy: 0.764000\n",
      "Loss: 0.238308, Train accuracy: 0.972111, val accuracy: 0.757000\n",
      "Loss: 0.203893, Train accuracy: 0.953556, val accuracy: 0.756000\n",
      "Loss: 0.073432, Train accuracy: 0.965889, val accuracy: 0.760000\n",
      "Loss: 0.285165, Train accuracy: 0.977667, val accuracy: 0.762000\n",
      "Loss: 0.146577, Train accuracy: 0.976111, val accuracy: 0.768000\n",
      "Loss: 0.066575, Train accuracy: 0.978222, val accuracy: 0.757000\n",
      "Loss: 0.182342, Train accuracy: 0.976111, val accuracy: 0.765000\n",
      "Loss: 0.243691, Train accuracy: 0.976111, val accuracy: 0.766000\n",
      "Loss: 0.155197, Train accuracy: 0.962111, val accuracy: 0.765000\n",
      "Loss: 0.189644, Train accuracy: 0.974556, val accuracy: 0.778000\n",
      "Loss: 0.106737, Train accuracy: 0.979778, val accuracy: 0.763000\n",
      "Loss: 0.045377, Train accuracy: 0.984889, val accuracy: 0.760000\n",
      "Loss: 0.145579, Train accuracy: 0.971444, val accuracy: 0.763000\n",
      "Loss: 0.093810, Train accuracy: 0.986333, val accuracy: 0.764000\n",
      "Loss: 0.062995, Train accuracy: 0.986222, val accuracy: 0.769000\n",
      "Loss: 0.063640, Train accuracy: 0.984556, val accuracy: 0.760000\n",
      "Loss: 0.078797, Train accuracy: 0.976889, val accuracy: 0.767000\n",
      "Loss: 0.478844, Train accuracy: 0.952333, val accuracy: 0.747000\n",
      "Loss: 0.042570, Train accuracy: 0.990111, val accuracy: 0.766000\n",
      "Loss: 0.035499, Train accuracy: 0.993000, val accuracy: 0.761000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-59b9cb363468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mhl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         bs=bs))\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best val acc = {}, epoch_n={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dlcourse_ai/assignments/assignment2/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dlcourse_ai/assignments/assignment2/model.py\u001b[0m in \u001b[0;36mcompute_loss_and_gradients\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dlcourse_ai/assignments/assignment2/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-1, 4e-1, 1e-2]\n",
    "reg_strength = [1e-7, 4e-7, 1e-8]\n",
    "learning_rate_decay = [0.999]\n",
    "hidden_layer_size = [100, 128, 175]\n",
    "num_epochs = 100\n",
    "batch_size = [64, 50, 80]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strength:\n",
    "        for lrd in learning_rate_decay:\n",
    "            for hl in hidden_layer_size:\n",
    "                for bs in batch_size:\n",
    "                    model = TwoLayerNet(n_input=train_X.shape[1], \n",
    "                            n_output=10,\n",
    "                            hidden_layer_size=hl,\n",
    "                            reg=rs)\n",
    "                    dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "                    trainer = Trainer(model, \n",
    "                                      dataset, \n",
    "                                      SGD(), \n",
    "                                      learning_rate=lr, \n",
    "                                      num_epochs=num_epochs, \n",
    "                                      batch_size=bs,\n",
    "                                      learning_rate_decay=lrd)\n",
    "                    print('__________________________________________________________________')\n",
    "                    print('''learning_rate={lr} reg_strength={rs} learning_rate_decay={lrd} hidden_layer_size={hl} batch_size={bs}'''.format(\n",
    "                        lr=lr,\n",
    "                        rs=rs,\n",
    "                        lrd=lrd,\n",
    "                        hl=hl,\n",
    "                        bs=bs))\n",
    "                    loss_history, train_history, val_history = trainer.fit()\n",
    "                    print('best val acc = {}, epoch_n={}'.format(max(val_history), np.argmax(val_history)))\n",
    "                    \n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "#print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.238640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289317, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.034614, Train accuracy: 0.227111, val accuracy: 0.227000\n",
      "Loss: 1.908860, Train accuracy: 0.290222, val accuracy: 0.295000\n",
      "Loss: 1.688448, Train accuracy: 0.381444, val accuracy: 0.367000\n",
      "Loss: 1.918162, Train accuracy: 0.448222, val accuracy: 0.452000\n",
      "Loss: 1.429039, Train accuracy: 0.524000, val accuracy: 0.517000\n",
      "Loss: 1.279020, Train accuracy: 0.581222, val accuracy: 0.577000\n",
      "Loss: 1.194392, Train accuracy: 0.620556, val accuracy: 0.598000\n",
      "Loss: 1.325787, Train accuracy: 0.630333, val accuracy: 0.618000\n",
      "Loss: 0.771738, Train accuracy: 0.678889, val accuracy: 0.659000\n",
      "Loss: 0.949286, Train accuracy: 0.694889, val accuracy: 0.675000\n",
      "Loss: 1.033222, Train accuracy: 0.695333, val accuracy: 0.671000\n",
      "Loss: 1.092214, Train accuracy: 0.716889, val accuracy: 0.682000\n",
      "Loss: 1.017662, Train accuracy: 0.712778, val accuracy: 0.692000\n",
      "Loss: 1.011926, Train accuracy: 0.735556, val accuracy: 0.694000\n",
      "Loss: 1.104439, Train accuracy: 0.748667, val accuracy: 0.708000\n",
      "Loss: 0.621700, Train accuracy: 0.738111, val accuracy: 0.694000\n",
      "Loss: 0.561395, Train accuracy: 0.725444, val accuracy: 0.676000\n",
      "Loss: 0.645521, Train accuracy: 0.725667, val accuracy: 0.691000\n",
      "Loss: 0.544585, Train accuracy: 0.760222, val accuracy: 0.718000\n",
      "Loss: 0.865281, Train accuracy: 0.770778, val accuracy: 0.706000\n",
      "Loss: 0.694610, Train accuracy: 0.765667, val accuracy: 0.718000\n",
      "Loss: 0.710409, Train accuracy: 0.805000, val accuracy: 0.734000\n",
      "Loss: 0.632850, Train accuracy: 0.789111, val accuracy: 0.716000\n",
      "Loss: 0.683390, Train accuracy: 0.803556, val accuracy: 0.715000\n",
      "Loss: 0.691852, Train accuracy: 0.825111, val accuracy: 0.746000\n",
      "Loss: 0.445134, Train accuracy: 0.825222, val accuracy: 0.722000\n",
      "Loss: 0.736453, Train accuracy: 0.835667, val accuracy: 0.741000\n",
      "Loss: 0.365851, Train accuracy: 0.850889, val accuracy: 0.749000\n",
      "Loss: 0.785000, Train accuracy: 0.846222, val accuracy: 0.733000\n",
      "Loss: 0.527183, Train accuracy: 0.860889, val accuracy: 0.765000\n",
      "Loss: 0.294322, Train accuracy: 0.861111, val accuracy: 0.740000\n",
      "Loss: 0.440767, Train accuracy: 0.853222, val accuracy: 0.735000\n",
      "Loss: 0.495855, Train accuracy: 0.862111, val accuracy: 0.742000\n",
      "Loss: 0.345395, Train accuracy: 0.867667, val accuracy: 0.751000\n",
      "Loss: 0.454539, Train accuracy: 0.878000, val accuracy: 0.740000\n",
      "Loss: 0.442942, Train accuracy: 0.886778, val accuracy: 0.760000\n",
      "Loss: 0.768912, Train accuracy: 0.892778, val accuracy: 0.748000\n",
      "Loss: 0.508831, Train accuracy: 0.875222, val accuracy: 0.735000\n",
      "Loss: 0.477963, Train accuracy: 0.865333, val accuracy: 0.720000\n",
      "Loss: 0.217711, Train accuracy: 0.892444, val accuracy: 0.755000\n",
      "Loss: 0.185289, Train accuracy: 0.900333, val accuracy: 0.756000\n",
      "Loss: 0.397732, Train accuracy: 0.890889, val accuracy: 0.743000\n",
      "Loss: 0.406483, Train accuracy: 0.904111, val accuracy: 0.753000\n",
      "Loss: 0.281660, Train accuracy: 0.886667, val accuracy: 0.746000\n",
      "Loss: 0.277123, Train accuracy: 0.890222, val accuracy: 0.747000\n",
      "Loss: 0.385713, Train accuracy: 0.885556, val accuracy: 0.744000\n",
      "Loss: 0.359031, Train accuracy: 0.913667, val accuracy: 0.755000\n",
      "Loss: 0.158902, Train accuracy: 0.923333, val accuracy: 0.757000\n",
      "Loss: 0.419421, Train accuracy: 0.853111, val accuracy: 0.727000\n",
      "Loss: 0.254330, Train accuracy: 0.922111, val accuracy: 0.755000\n",
      "Loss: 0.302681, Train accuracy: 0.931111, val accuracy: 0.764000\n",
      "Loss: 0.105301, Train accuracy: 0.924556, val accuracy: 0.760000\n",
      "Loss: 0.229010, Train accuracy: 0.926667, val accuracy: 0.771000\n",
      "Loss: 0.434575, Train accuracy: 0.925222, val accuracy: 0.757000\n",
      "Loss: 0.260494, Train accuracy: 0.935556, val accuracy: 0.759000\n",
      "Loss: 0.135621, Train accuracy: 0.930778, val accuracy: 0.756000\n",
      "Loss: 0.292007, Train accuracy: 0.926222, val accuracy: 0.753000\n",
      "Loss: 0.573597, Train accuracy: 0.865333, val accuracy: 0.717000\n",
      "Loss: 0.163955, Train accuracy: 0.945333, val accuracy: 0.775000\n",
      "Loss: 0.660224, Train accuracy: 0.936556, val accuracy: 0.763000\n",
      "Loss: 0.386098, Train accuracy: 0.876000, val accuracy: 0.731000\n",
      "Loss: 0.169706, Train accuracy: 0.948333, val accuracy: 0.776000\n",
      "Loss: 0.357437, Train accuracy: 0.932556, val accuracy: 0.768000\n",
      "Loss: 0.220299, Train accuracy: 0.953000, val accuracy: 0.774000\n",
      "Loss: 0.124187, Train accuracy: 0.915333, val accuracy: 0.748000\n",
      "Loss: 0.227345, Train accuracy: 0.936556, val accuracy: 0.756000\n",
      "Loss: 0.176906, Train accuracy: 0.917889, val accuracy: 0.747000\n",
      "Loss: 0.109924, Train accuracy: 0.963000, val accuracy: 0.777000\n",
      "Loss: 0.295664, Train accuracy: 0.936444, val accuracy: 0.759000\n",
      "Loss: 0.154516, Train accuracy: 0.950333, val accuracy: 0.757000\n",
      "Loss: 0.177836, Train accuracy: 0.921778, val accuracy: 0.738000\n",
      "Loss: 0.116514, Train accuracy: 0.959333, val accuracy: 0.767000\n",
      "Loss: 0.158249, Train accuracy: 0.968333, val accuracy: 0.774000\n",
      "Loss: 0.089006, Train accuracy: 0.963778, val accuracy: 0.759000\n",
      "Loss: 0.401226, Train accuracy: 0.924556, val accuracy: 0.740000\n",
      "Loss: 0.173779, Train accuracy: 0.955667, val accuracy: 0.754000\n",
      "Loss: 0.151170, Train accuracy: 0.940444, val accuracy: 0.758000\n",
      "Loss: 0.228257, Train accuracy: 0.967778, val accuracy: 0.768000\n",
      "Loss: 0.188996, Train accuracy: 0.967556, val accuracy: 0.770000\n",
      "Loss: 0.134860, Train accuracy: 0.967333, val accuracy: 0.774000\n",
      "Loss: 0.108443, Train accuracy: 0.969444, val accuracy: 0.762000\n",
      "Loss: 0.330328, Train accuracy: 0.956556, val accuracy: 0.758000\n",
      "Loss: 0.210039, Train accuracy: 0.972556, val accuracy: 0.775000\n",
      "Loss: 0.128030, Train accuracy: 0.973556, val accuracy: 0.778000\n",
      "Loss: 0.070917, Train accuracy: 0.966778, val accuracy: 0.760000\n",
      "Loss: 0.061019, Train accuracy: 0.968111, val accuracy: 0.774000\n",
      "Loss: 0.136924, Train accuracy: 0.968222, val accuracy: 0.772000\n",
      "Loss: 0.094843, Train accuracy: 0.973667, val accuracy: 0.763000\n",
      "Loss: 0.093900, Train accuracy: 0.972222, val accuracy: 0.761000\n",
      "Loss: 0.124751, Train accuracy: 0.981222, val accuracy: 0.774000\n",
      "Loss: 0.170012, Train accuracy: 0.975111, val accuracy: 0.764000\n",
      "Loss: 0.219781, Train accuracy: 0.936778, val accuracy: 0.747000\n",
      "Loss: 0.281899, Train accuracy: 0.940222, val accuracy: 0.748000\n",
      "Loss: 0.096261, Train accuracy: 0.978778, val accuracy: 0.763000\n",
      "Loss: 0.035567, Train accuracy: 0.980889, val accuracy: 0.772000\n",
      "Loss: 0.132736, Train accuracy: 0.954556, val accuracy: 0.762000\n",
      "Loss: 0.182259, Train accuracy: 0.983778, val accuracy: 0.761000\n",
      "Loss: 0.220879, Train accuracy: 0.970667, val accuracy: 0.761000\n"
     ]
    }
   ],
   "source": [
    "# Assume that the best model is achieved with the following parameters\n",
    "# learning_rate=0.1 \n",
    "# reg_strength=1e-07 \n",
    "# learning_rate_decay=0.999 \n",
    "# hidden_layer_size=175 \n",
    "# batch_size=64\n",
    "# num_epochs = 100\n",
    "\n",
    "model = TwoLayerNet(n_input=train_X.shape[1], \n",
    "                            n_output=10,\n",
    "                            hidden_layer_size=175,\n",
    "                            reg=1e-7)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, \n",
    "                  dataset, \n",
    "                  SGD(), \n",
    "                  learning_rate=0.1, \n",
    "                  num_epochs=100, \n",
    "                  batch_size=64,\n",
    "                  learning_rate_decay=0.999)\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb90ae07e10>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.743000\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
